{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install gradio\n!pip install huggingface_hub\n!huggingface-cli login --token \"your-hf-token\"\n!pip install transformers gradio accelerate --quiet\n!pip install transformers sentence-transformers faiss-cpu datasets\n!pip install requests beautifulsoup4 nltk sentence-transformers faiss-cpu transformers torch gradio pyspellchecker\n!pip install streamlit sentence-transformers scikit-learn faiss-cpu transformers nltk tenacity pandas openpyxl torch beautifulsoup4 requests\n!pip install -q sentence-transformers scikit-learn faiss-cpu gradio transformers nltk tenacity openpyxl rank_bm25\n!pip install pandas matplotlib openpyxl\n!pip install -q sentence-transformers scikit-learn faiss-cpu gradio transformers nltk tenacity openpyxl","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# ==============================================\n# SynecxAI Final RAG Chatbot with Full Metrics\n# ==============================================\nimport os, time, urllib.parse, pandas as pd, requests, torch, gradio as gr\nfrom bs4 import BeautifulSoup\nfrom nltk.tokenize import sent_tokenize\nimport nltk\nfrom sentence_transformers import SentenceTransformer, util\nimport faiss\nfrom transformers import pipeline\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom tenacity import retry, stop_after_attempt, wait_fixed\nfrom rank_bm25 import BM25Okapi\nfrom collections import defaultdict\nfrom openpyxl import load_workbook\n\n# ========== Setup ==========\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nnltk.download(\"punkt\", quiet=True)\n\n# ========== NLP ==========\nintent_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\nINTENT_LABELS = [\"product_info\", \"pricing\", \"support\", \"career\", \"contact\", \"case_study\", \"blog\", \"general\"]\n\ndef detect_intent(text): return intent_classifier(text, candidate_labels=INTENT_LABELS)[\"labels\"][0]\ntry:\n    import spacy\n    nlp = spacy.load(\"en_core_web_sm\")\nexcept:\n    nlp = None\ndef extract_entities(text): return [(e.text, e.label_) for e in nlp(text).ents] if nlp else []\n\n# ========== Web Scraping ==========\n@retry(stop=stop_after_attempt(3), wait=wait_fixed(2))\ndef get_website_text(url):\n    try:\n        r = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"}, timeout=30)\n        r.raise_for_status()\n        soup = BeautifulSoup(r.text, \"html.parser\")\n        return [s.strip() for s in sent_tokenize(soup.get_text(\" \")) if len(s.strip()) > 30]\n    except: return []\n\nURLS = [\n    \"https://synecxailabs.io\", \"https://synecxailabs.io/about-us\", \"https://synecxailabs.io/blog\",\n    \"https://synecxailabs.io/CaseStudy\", \"https://synecxailabs.io/career\", \"https://synecxailabs.io/contact\",\n    \"https://synecxailabs.io/retail\", \"https://docsynecx.com/\", \"https://docsynecx.com/platforms\",\n    \"https://docsynecx.com/#solutions\", \"https://docsynecx.com/blog\", \"https://docsynecx.com/pricing\",\n    \"https://docsynecx.com/contact\"\n]\n\ndocuments = []\nfor url in URLS:\n    documents.extend(get_website_text(url))\nrag_enabled = False\n\n# ========== Indexing ==========\nif documents:\n    embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n    doc_emb = embedder.encode(documents, show_progress_bar=True)\n    index = faiss.IndexFlatL2(doc_emb.shape[1]); index.add(doc_emb)\n    bm25 = BM25Okapi([d.split() for d in documents])\n    rag_enabled = True\n\n# ========== Retrieval ==========\ndef retrieve_context(query, top_k=3):\n    if not rag_enabled: return \"No relevant information.\"\n    q_emb = embedder.encode([query])\n    _, dense_idx = index.search(q_emb, top_k * 2)\n    sparse_scores = bm25.get_scores(query.split())\n    sparse_idx = sorted(range(len(sparse_scores)), key=lambda i: sparse_scores[i], reverse=True)[:top_k*2]\n    candidates = list(set(dense_idx[0]).union(sparse_idx))\n    cand_emb = embedder.encode([documents[i] for i in candidates])\n    sims = cosine_similarity(q_emb, cand_emb)[0]\n    top = sorted(zip(candidates, sims), key=lambda x: x[1], reverse=True)[:top_k]\n    return \"\\n\".join([documents[i] for i, _ in top])[:2000]\n\n# ========== LLaMA ==========\nllama_loaded = False\ntry:\n    llama = pipeline(\"text-generation\", model=\"meta-llama/Llama-3.2-3B-Instruct\", torch_dtype=torch.float16, device_map=\"auto\")\n    llama_loaded = True\nexcept Exception as e:\n    print(\"Model load failed:\", e)\n\ndef rag_response(query):\n    if not llama_loaded: return \"Model error.\", \"\"\n    context = retrieve_context(query)\n    prompt = (\n        \"You are the SynecxAI virtual assistant.\\n\"\n        \"Answer concisely using ONLY the context.\\n\\n\"\n        f\"Context:\\n{context}\\n\\n\"\n        f\"Question: {query}\\nAnswer:\"\n    )\n    output = llama(prompt, max_new_tokens=128, temperature=0.7, return_full_text=False)\n    return output[0][\"generated_text\"].strip(), context\n\n# ========== Metrics ==========\ninteraction_logs = []\nuser_sessions = defaultdict(list)\nprevious_questions = {}\nEXCEL_PATH = \"interaction_metrics.xlsx\"\n\ndef semantic_similarity(a, b): return util.cos_sim(embedder.encode(a), embedder.encode(b)).item()\n\ndef calculate_metrics():\n    df = pd.DataFrame(interaction_logs)\n    metrics = {}\n\n    metrics[\"First Response Time\"] = df[\"response_time\"].iloc[0] if not df.empty else None\n    metrics[\"Average Response Time\"] = df[\"response_time\"].mean()\n    metrics[\"Task Completion Rate (%)\"] = df[\"task_completed\"].mean() * 100\n    metrics[\"Fallback Rate (%)\"] = df[\"fallback\"].mean() * 100\n    metrics[\"Intent Accuracy (%)\"] = df[\"intent_correct\"].dropna().mean() * 100 if \"intent_correct\" in df else None\n    metrics[\"Entity Accuracy (%)\"] = df[\"entity_correct\"].dropna().mean() * 100 if \"entity_correct\" in df else None\n\n    session_counts = df[\"user_id\"].value_counts()\n    metrics[\"User Retention Rate (%)\"] = (session_counts > 1).mean() * 100\n    metrics[\"Bounce Rate (%)\"] = (session_counts == 1).mean() * 100\n    metrics[\"Deflection Rate (%)\"] = df[\"task_completed\"].mean() * 100\n    metrics[\"Semantic Similarity Avg\"] = df[\"semantic_similarity\"].mean()\n\n    return metrics\n\ndef log_interaction(user_input, bot_response, context, start, end, fallback=False, user_id=\"guest\"):\n    user_sessions[user_id].append((user_input, bot_response))\n    sim = semantic_similarity(user_input, bot_response)\n\n    consistency = None\n    if user_input in previous_questions:\n        consistency = semantic_similarity(bot_response, previous_questions[user_input])\n    previous_questions[user_input] = bot_response\n\n    log_row = {\n        \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n        \"user_id\": user_id,\n        \"user_input\": user_input,\n        \"bot_response\": bot_response,\n        \"context\": context,\n        \"response_time\": round(end - start, 2),\n        \"fallback\": fallback,\n        \"task_completed\": not fallback,\n        \"semantic_similarity\": round(sim, 4),\n        \"consistency_score\": round(consistency, 4) if consistency else None,\n        \"intent_prediction\": detect_intent(user_input),\n        \"entities_extracted\": extract_entities(user_input),\n        \"intent_correct\": None,\n        \"entity_correct\": None,\n    }\n\n    interaction_logs.append(log_row)\n    metrics = calculate_metrics()\n\n    try:\n        if os.path.exists(EXCEL_PATH):\n            with pd.ExcelWriter(EXCEL_PATH, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"overlay\") as writer:\n                pd.DataFrame([log_row]).to_excel(writer, sheet_name=\"Logs\", index=False, header=not writer.sheets.get(\"Logs\"))\n                pd.DataFrame([metrics]).to_excel(writer, sheet_name=\"Metrics\", index=False)\n        else:\n            with pd.ExcelWriter(EXCEL_PATH, engine=\"openpyxl\") as writer:\n                pd.DataFrame([log_row]).to_excel(writer, sheet_name=\"Logs\", index=False)\n                pd.DataFrame([metrics]).to_excel(writer, sheet_name=\"Metrics\", index=False)\n    except Exception as e:\n        print(f\"‚ùå Excel save error: {e}\")\n\n# ========== Gradio ==========\ndef chat_fn(user_msg, chat_history):\n    start = time.time()\n    try:\n        answer, context = rag_response(user_msg)\n        end = time.time()\n        chat_history.append((user_msg, answer))\n        log_interaction(user_msg, answer, context, start, end)\n    except Exception as e:\n        end = time.time()\n        error_msg = f\"‚ùå Error: {e}\"\n        chat_history.append((user_msg, error_msg))\n        log_interaction(user_msg, error_msg, \"\", start, end, fallback=True)\n    return chat_history, \"\"\n\nwith gr.Blocks() as demo:\n    gr.Markdown(\"## ü§ñ SynecxAI Assistant (Metrics-Enabled)\")\n    chatbot = gr.Chatbot()\n    msg = gr.Textbox(label=\"Ask me anything\", placeholder=\"e.g., What services do you offer?\", lines=1)\n    clear = gr.Button(\"üßπ Clear\")\n\n    msg.submit(chat_fn, [msg, chatbot], [chatbot, msg])\n    clear.click(lambda: ([], \"\"), None, [chatbot, msg])\n\nprint(\"üöÄ Launching ‚Ä¶\")\ndemo.launch(share=True)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}